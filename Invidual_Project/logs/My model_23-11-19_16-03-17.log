> training arguments:
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 0.0001
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1700380998292
>>> index: 0
>>> log_name: My model_23-11-19_16-03-17.log
1/10 - 10.00%
[train] loss: 2.1434, acc: 36.11
[test] loss: 0.7109, acc: 77.08
> training arguments:
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 0.0001
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: True
>>> workers: 0
>>> timestamp: 1700381899378
>>> index: 0
>>> log_name: My model_23-11-19_16-18-18.log
> training arguments:
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 0.0001
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1700382145879
>>> index: 0
>>> log_name: My model_23-11-19_16-22-25.log
1/10 - 10.00%
[train] loss: 2.3010, acc: 28.61
[test] loss: 1.0142, acc: 70.00
> training arguments:
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 0.0001
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1700382489475
>>> index: 0
>>> log_name: My model_23-11-19_16-28-08.log
> training arguments:
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 0.0001
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1700382749376
>>> index: 0
>>> log_name: My model_23-11-19_16-32-28.log
> training arguments:
>>> train_batch_size: 32
>>> test_batch_size: 32
>>> num_epoch: 10
>>> lr: 0.0001
>>> weight_decay: 0.01
>>> device: cpu
>>> backend: False
>>> workers: 0
>>> timestamp: 1700382822360
>>> index: 0
>>> log_name: My model_23-11-19_16-33-42.log
